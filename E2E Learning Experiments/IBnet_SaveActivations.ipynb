{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcash8/Info-Theory-Project/blob/main/E2E%20Learning%20Experiments/IBnet_SaveActivations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqm7yoS0dibX",
        "outputId": "6da56b61-69ce-4106-ae47-c8127396a3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "IxLhP4BnyGRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/utils.py /content/\n",
        "!cp drive/MyDrive/loggingreporter.py /content/\n",
        "!cp drive/MyDrive/datasets/ -r /content/"
      ],
      "metadata": {
        "id": "7CDJbx-8fJKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pathlib2\n",
        "!pip install tensorflow==2.1.0\n",
        "!pip install keras==2.3.1"
      ],
      "metadata": {
        "id": "AXI_SXP2iXPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_IUHfJbcD2Q"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "import utils\n",
        "import loggingreporter \n",
        "\n",
        "cfg = {}\n",
        "\n",
        "cfg['SGD_LEARNINGRATE'] = 0.0004\n",
        "cfg['NUM_EPOCHS']       = 10000\n",
        "cfg['FULL_MI']          = True\n",
        "\n",
        "#cfg['ACTIVATION'] = 'tanh'\n",
        "#cfg['ACTIVATION'] = 'relu'\n",
        "#cfg['ACTIVATION'] = 'softsign'\n",
        "cfg['ACTIVATION'] = 'softplus'\n",
        "\n",
        "# How many hidden neurons to put into each of the layers\n",
        "cfg['LAYER_DIMS'] = [10,7,5,4,3] # original IB network\n",
        "ARCH_NAME =  '-'.join(map(str,cfg['LAYER_DIMS']))\n",
        "\n",
        "trn, tst = utils.get_IB_data('2017_12_21_16_51_3_275766')\n",
        "\n",
        "cfg['SGD_BATCHSIZE']    = trn.X.shape[0] #full batch\n",
        "#cfg['SGD_BATCHSIZE']    = 256 #uncomment for SGD\n",
        "\n",
        "# Where to save activation and weights data\n",
        "cfg['SAVE_DIR'] = 'rawdata/' + cfg['ACTIVATION'] + '_' + ARCH_NAME "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-s-5GNLNcD2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73860be8-93db-4598-fb57-f0f1edcfaff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 10)                130       \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 7)                 77        \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 5)                 40        \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 4)                 24        \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 2)                 8         \n",
            "=================================================================\n",
            "Total params: 294\n",
            "Trainable params: 294\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_layer = keras.layers.Input((trn.X.shape[1],))\n",
        "clayer = input_layer\n",
        "for n in cfg['LAYER_DIMS']:\n",
        "    clayer = keras.layers.Dense(n, \n",
        "                                activation=cfg['ACTIVATION'],\n",
        "                                kernel_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=1/np.sqrt(float(n)), seed=None),\n",
        "                                bias_initializer='zeros'\n",
        "                               )(clayer)\n",
        "output_layer = keras.layers.Dense(trn.nb_classes, activation='softmax')(clayer)\n",
        "\n",
        "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=cfg['SGD_LEARNINGRATE'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "BwOeFmg8cD2Y"
      },
      "outputs": [],
      "source": [
        "def do_report(epoch):\n",
        "    # Only log activity for some epochs.  Mainly this is to make things run faster.\n",
        "    if epoch < 20:       # Log for all first 20 epochs\n",
        "        return True\n",
        "    elif epoch < 100:    # Then for every 5th epoch\n",
        "        return (epoch % 5 == 0)\n",
        "    elif epoch < 2000:    # Then every 10th\n",
        "        return (epoch % 20 == 0)\n",
        "    else:                # Then every 100th\n",
        "        return (epoch % 100 == 0)\n",
        "    \n",
        "reporter = loggingreporter.LoggingReporter(cfg=cfg, \n",
        "                                          trn=trn, \n",
        "                                          tst=tst, \n",
        "                                          do_save_func=do_report)\n",
        "r = model.fit(x=trn.X, y=trn.Y, \n",
        "              verbose    = 2, \n",
        "              batch_size = cfg['SGD_BATCHSIZE'],\n",
        "              epochs     = cfg['NUM_EPOCHS'],\n",
        "              # validation_data=(tst.X, tst.Y),\n",
        "              callbacks  = [reporter,])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#Compute MI"
      ],
      "metadata": {
        "id": "G3XjEa-JyBR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/kde.py /content/\n",
        "!cp drive/MyDrive/simplebinmi.py /content/"
      ],
      "metadata": {
        "id": "Xerimmb0z9lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import _pickle as cPickle\n",
        "from collections import defaultdict, OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "\n",
        "import kde\n",
        "import simplebinmi\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "import utils\n",
        "\n",
        "# load data network was trained on\n",
        "trn, tst = utils.get_IB_data('2017_12_21_16_51_3_275766')\n",
        "# trn, tst = utils.get_mnist()\n",
        "\n",
        "# calc MI for train and test. Save_activations must have been run with cfg['FULL_MI'] = True\n",
        "FULL_MI = True\n",
        "\n",
        "# Which measure to plot\n",
        "infoplane_measure = 'upper'\n",
        "#infoplane_measure = 'bin'\n",
        "\n",
        "DO_SAVE        = True    # Whether to save plots or just show them\n",
        "DO_LOWER       = (infoplane_measure == 'lower')   # Whether to compute lower bounds also\n",
        "DO_BINNED      = (infoplane_measure == 'bin')     # Whether to compute MI estimates based on binning\n",
        "\n",
        "MAX_EPOCHS = 10000      # Max number of epoch for which to compute mutual information measure\n",
        "NUM_LABELS = 2\n",
        "# MAX_EPOCHS = 1000\n",
        "COLORBAR_MAX_EPOCHS = 10000\n",
        "\n",
        "# Directories from which to load saved layer activity\n",
        "# ARCH = '1024-20-20-20'\n",
        "ARCH = '10-7-5-4-3'\n",
        "#ARCH = '20-20-20-20-20-20'\n",
        "#ARCH = '32-28-24-20-16-12'\n",
        "#ARCH = '32-28-24-20-16-12-8-8'\n",
        "DIR_TEMPLATE = '%%s_%s'%ARCH\n",
        "\n",
        "# Functions to return upper and lower bounds on entropy of layer activity\n",
        "noise_variance = 1e-3                    # Added Gaussian noise variance\n",
        "binsize = 0.07                           # size of bins for binning method\n",
        "Klayer_activity = K.placeholder(ndim=2)  # Keras placeholder \n",
        "entropy_func_upper = K.function([Klayer_activity,], [kde.entropy_estimator_kl(Klayer_activity, noise_variance),])\n",
        "entropy_func_lower = K.function([Klayer_activity,], [kde.entropy_estimator_bd(Klayer_activity, noise_variance),])\n",
        "\n",
        "# nats to bits conversion factor\n",
        "nats2bits = 1.0/np.log(2) \n",
        "\n",
        "# Save indexes of tests data for each of the output classes\n",
        "saved_labelixs = {}\n",
        "\n",
        "y = tst.y\n",
        "Y = tst.Y\n",
        "if FULL_MI:\n",
        "    full = utils.construct_full_dataset(trn,tst)\n",
        "    y = full.y\n",
        "    Y = full.Y\n",
        "\n",
        "for i in range(NUM_LABELS):\n",
        "    saved_labelixs[i] = y == i\n",
        "\n",
        "labelprobs = np.mean(Y, axis=0)"
      ],
      "metadata": {
        "id": "0cSUTOS-yA78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PLOT_LAYERS    = None     # Which layers to plot.  If None, all saved layers are plotted \n",
        "\n",
        "# Data structure used to store results, add more measures[] for the activation you want to plot\n",
        "measures = OrderedDict()\n",
        "measures['softsign'] = {}\n",
        "measures['softplus'] = {}"
      ],
      "metadata": {
        "id": "NCtqqMiY0SEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for activation in measures.keys():\n",
        "    cur_dir = 'rawdata/' + DIR_TEMPLATE % activation\n",
        "    if not os.path.exists(cur_dir):\n",
        "        print(\"Directory %s not found\" % cur_dir)\n",
        "        continue\n",
        "        \n",
        "    # Load files saved during each epoch, and compute MI measures of the activity in that epoch\n",
        "    print('*** Doing %s ***' % cur_dir)\n",
        "    for epochfile in sorted(os.listdir(cur_dir)):\n",
        "        if not epochfile.startswith('epoch'):\n",
        "            continue\n",
        "            \n",
        "        fname = cur_dir + \"/\" + epochfile\n",
        "        with open(fname, 'rb') as f:\n",
        "            d = cPickle.load(f)\n",
        "\n",
        "        epoch = d['epoch']\n",
        "        if epoch in measures[activation]: # Skip this epoch if its already been processed\n",
        "            continue                      # this is a trick to allow us to rerun this cell multiple times)\n",
        "            \n",
        "        if epoch > MAX_EPOCHS:\n",
        "            continue\n",
        "\n",
        "        print(\"Doing\", fname)\n",
        "        \n",
        "        num_layers = len(d['data']['activity_tst'])\n",
        "\n",
        "        if PLOT_LAYERS is None:\n",
        "            PLOT_LAYERS = []\n",
        "            for lndx in range(num_layers):\n",
        "                #if d['data']['activity_tst'][lndx].shape[1] < 200 and lndx != num_layers - 1:\n",
        "                PLOT_LAYERS.append(lndx)\n",
        "                \n",
        "        cepochdata = defaultdict(list)\n",
        "        for lndx in range(num_layers):\n",
        "            activity = d['data']['activity_tst'][lndx]\n",
        "\n",
        "            # Compute marginal entropies\n",
        "            h_upper = entropy_func_upper([activity,])[0]\n",
        "            if DO_LOWER:\n",
        "                h_lower = entropy_func_lower([activity,])[0]\n",
        "                \n",
        "            # Layer activity given input. This is simply the entropy of the Gaussian noise\n",
        "            hM_given_X = kde.kde_condentropy(activity, noise_variance)\n",
        "\n",
        "            # Compute conditional entropies of layer activity given output\n",
        "            hM_given_Y_upper=0.\n",
        "            for i in range(NUM_LABELS):\n",
        "                hcond_upper = entropy_func_upper([activity[saved_labelixs[i],:],])[0]\n",
        "                hM_given_Y_upper += labelprobs[i] * hcond_upper\n",
        "                \n",
        "            if DO_LOWER:\n",
        "                hM_given_Y_lower=0.\n",
        "                for i in range(NUM_LABELS):\n",
        "                    hcond_lower = entropy_func_lower([activity[saved_labelixs[i],:],])[0]\n",
        "                    hM_given_Y_lower += labelprobs[i] * hcond_lower\n",
        "                \n",
        "            cepochdata['MI_XM_upper'].append( nats2bits * (h_upper - hM_given_X) )\n",
        "            cepochdata['MI_YM_upper'].append( nats2bits * (h_upper - hM_given_Y_upper) )\n",
        "            cepochdata['H_M_upper'  ].append( nats2bits * h_upper )\n",
        "\n",
        "            pstr = 'upper: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_upper'][-1], cepochdata['MI_YM_upper'][-1])\n",
        "            if DO_LOWER:  # Compute lower bounds\n",
        "                cepochdata['MI_XM_lower'].append( nats2bits * (h_lower - hM_given_X) )\n",
        "                cepochdata['MI_YM_lower'].append( nats2bits * (h_lower - hM_given_Y_lower) )\n",
        "                cepochdata['H_M_lower'  ].append( nats2bits * h_lower )\n",
        "                pstr += ' | lower: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_lower'][-1], cepochdata['MI_YM_lower'][-1])\n",
        "\n",
        "            if DO_BINNED: # Compute binned estimates\n",
        "                binxm, binym = simplebinmi.bin_calc_information2(saved_labelixs, activity, binsize)\n",
        "                cepochdata['MI_XM_bin'].append( nats2bits * binxm )\n",
        "                cepochdata['MI_YM_bin'].append( nats2bits * binym )\n",
        "                pstr += ' | bin: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_bin'][-1], cepochdata['MI_YM_bin'][-1])\n",
        "                        \n",
        "            print('- Layer %d %s' % (lndx, pstr) )\n",
        "\n",
        "        measures[activation][epoch] = cepochdata"
      ],
      "metadata": {
        "id": "yFFdk1UP0We6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8bc20b3-28d3-4149-b71d-7d65c5587717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory rawdata/softsign_10-7-5-4-3 not found\n",
            "Directory rawdata/softplus_10-7-5-4-3 not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot infoplanes"
      ],
      "metadata": {
        "id": "l-L1BEbT1zjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epoch = max( (max(vals.keys()) if len(vals) else 0) for vals in measures.values())\n",
        "sm = plt.cm.ScalarMappable(cmap='gnuplot', norm=plt.Normalize(vmin=0, vmax=COLORBAR_MAX_EPOCHS))\n",
        "sm._A = []\n",
        "\n",
        "fig=plt.figure(figsize=(10,5))\n",
        "for actndx, (activation, vals) in enumerate(measures.items()):\n",
        "    epochs = sorted(vals.keys())\n",
        "    if not len(epochs):\n",
        "        continue\n",
        "    plt.subplot(1,2,actndx+1)    \n",
        "    for epoch in epochs:\n",
        "        c = sm.to_rgba(epoch)\n",
        "        xmvals = np.array(vals[epoch]['MI_XM_'+infoplane_measure])[PLOT_LAYERS]\n",
        "        ymvals = np.array(vals[epoch]['MI_YM_'+infoplane_measure])[PLOT_LAYERS]\n",
        "        print(xmvals.shape)\n",
        "        plt.plot(xmvals, ymvals, c=c, alpha=0.1, zorder=1)\n",
        "        plt.scatter(xmvals, ymvals, s=20, facecolors=[c for _ in PLOT_LAYERS], edgecolor='none', zorder=2)\n",
        "\n",
        "    plt.ylim([0, 1])\n",
        "    plt.xlim([0, 12])\n",
        "#     plt.ylim([0, 3.5])\n",
        "#     plt.xlim([0, 14])\n",
        "    plt.xlabel('I(X;M)')\n",
        "    plt.ylabel('I(Y;M)')\n",
        "    plt.title(activation)\n",
        "    \n",
        "cbaxes = fig.add_axes([1.0, 0.125, 0.03, 0.8]) \n",
        "plt.colorbar(sm, label='Epoch', cax=cbaxes)\n",
        "plt.tight_layout()\n",
        "\n",
        "!mkdir /content/plots\n",
        "if DO_SAVE:\n",
        "    plt.savefig('plots/' + DIR_TEMPLATE % ('infoplane_'+ARCH+'ss and ssp batch'),bbox_inches='tight')\n",
        "!cp /content/plots -r drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "g9FZOGHe1uiz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "IBnet_SaveActivations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}