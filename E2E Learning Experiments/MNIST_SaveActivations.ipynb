{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcash8/Info-Theory-Project/blob/main/E2E%20Learning%20Experiments/MNIST_SaveActivations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9fkXZ0qUTHo",
        "outputId": "06e1a533-e608-4e78-b062-ec66e36759cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save Action"
      ],
      "metadata": {
        "id": "Iz3fHY0ln2dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pathlib2\n",
        "!pip install tensorflow==2.1.0\n",
        "!pip install keras==2.3.1"
      ],
      "metadata": {
        "id": "eWA4sc-BkXz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/utils.py /content/\n",
        "!cp drive/MyDrive/loggingreporter.py /content/"
      ],
      "metadata": {
        "id": "i0oCi8oW6yxe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import utils\n",
        "import loggingreporter "
      ],
      "metadata": {
        "id": "-8m6OwwXnUyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bc0828-d2c6-4ad2-f59b-1b79e0f476ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ppBP2V40i25Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c315f679-331a-48e3-98cd-62c31ff64f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "cfg = {}\n",
        "\n",
        "cfg['SGD_LEARNINGRATE'] = 0.001\n",
        "cfg['NUM_EPOCHS']       = 8000\n",
        "\n",
        "cfg['ACTIVATION'] = 'softsign' #change to tanh, relu, softsign, or softplus\n",
        "# How many hidden neurons to put into each of the layers\n",
        "cfg['LAYER_DIMS'] = [1024, 20, 20, 20]\n",
        "#cfg['LAYER_DIMS'] = [1024, 512, 512, 512]\n",
        "#cfg['LAYER_DIMS'] = [32, 28, 24, 20, 16, 12, 8, 8]\n",
        "#cfg['LAYER_DIMS'] = [128, 64, 32, 16, 16] # 0.967 w. 128\n",
        "#cfg['LAYER_DIMS'] = [20, 20, 20, 20, 20, 20] # 0.967 w. 128\n",
        "ARCH_NAME =  '-'.join(map(str,cfg['LAYER_DIMS']))\n",
        "trn, tst= utils.get_mnist()\n",
        "cfg['SGD_BATCHSIZE']    = trn.X.shape[0]\n",
        "# Where to save activation and weights data\n",
        "cfg['SAVE_DIR'] = 'rawdata/' + cfg['ACTIVATION'] + '_' + ARCH_NAME "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTSRXMYyi25Z"
      },
      "outputs": [],
      "source": [
        "input_layer  = keras.layers.Input((trn.X.shape[1],))\n",
        "clayer = input_layer\n",
        "for n in cfg['LAYER_DIMS']:\n",
        "    clayer = keras.layers.Dense(n, activation=cfg['ACTIVATION'])(clayer)\n",
        "output_layer = keras.layers.Dense(trn.nb_classes, activation='softmax')(clayer)\n",
        "\n",
        "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "optimizer = tf.keras.optimizers.SGD(lr=cfg['SGD_LEARNINGRATE'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "rqH1ig0ii25a"
      },
      "outputs": [],
      "source": [
        "def do_report(epoch):\n",
        "    # Only log activity for some epochs.  Mainly this is to make things run faster.\n",
        "    if epoch < 20:       # Log for all first 20 epochs\n",
        "        return True\n",
        "    elif epoch < 100:    # Then for every 5th epoch\n",
        "        return (epoch % 5 == 0)\n",
        "    elif epoch < 200:    # Then every 10th\n",
        "        return (epoch % 10 == 0)\n",
        "    else:                # Then every 100th\n",
        "        return (epoch % 100 == 0)\n",
        "    \n",
        "reporter = loggingreporter.LoggingReporter(cfg=cfg, \n",
        "                                          trn=trn, \n",
        "                                          tst=tst, \n",
        "                                          do_save_func=do_report)\n",
        "r = model.fit(x=trn.X, y=trn.Y, \n",
        "              verbose    = 2, \n",
        "              batch_size = cfg['SGD_BATCHSIZE'],\n",
        "              epochs     = cfg['NUM_EPOCHS'],\n",
        "              callbacks  = [reporter,])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compute MI and Plot"
      ],
      "metadata": {
        "id": "GO7cm97JnzN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/kde.py /content/\n",
        "!cp drive/MyDrive/simplebinmi.py /content/"
      ],
      "metadata": {
        "id": "6fsz0ALEAjug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import _pickle as cPickle\n",
        "from collections import defaultdict, OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "\n",
        "import kde\n",
        "import simplebinmi\n",
        "\n",
        "import utils\n",
        "trn, tst = utils.get_mnist()\n",
        "\n",
        "# Which measure to plot\n",
        "#infoplane_measure = 'upper'\n",
        "infoplane_measure = 'bin'\n",
        "\n",
        "DO_SAVE        = True    # Whether to save plots or just show them\n",
        "DO_LOWER       = True    # (infoplane_measure == 'lower')   # Whether to compute lower bounds also\n",
        "DO_BINNED      = True    #(infoplane_measure == 'bin')     # Whether to compute MI estimates based on binning\n",
        "\n",
        "MAX_EPOCHS = 8000    #adjust for epochs used in training\n",
        "# MAX_EPOCHS = 1000\n",
        "COLORBAR_MAX_EPOCHS = 8000\n",
        "\n",
        "# Directories from which to load saved layer activity\n",
        "ARCH = '1024-20-20-20'\n",
        "DIR_TEMPLATE = '%%s_%s'%ARCH\n",
        "\n",
        "# Functions to return upper and lower bounds on entropy of layer activity\n",
        "noise_variance = 1e-1                    # Added Gaussian noise variance\n",
        "Klayer_activity = K.placeholder(ndim=2)  # Keras placeholder \n",
        "entropy_func_upper = K.function([Klayer_activity,], [kde.entropy_estimator_kl(Klayer_activity, noise_variance),])\n",
        "entropy_func_lower = K.function([Klayer_activity,], [kde.entropy_estimator_bd(Klayer_activity, noise_variance),])\n",
        "\n",
        "\n",
        "# nats to bits conversion factor\n",
        "nats2bits = 1.0/np.log(2) \n",
        "\n",
        "\n",
        "# Save indexes of tests data for each of the output classes\n",
        "saved_labelixs = {}\n",
        "for i in range(10):\n",
        "    saved_labelixs[i] = tst.y == i\n",
        "\n",
        "labelprobs = np.mean(tst.Y, axis=0)"
      ],
      "metadata": {
        "id": "sawSY8tqn1Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PLOT_LAYERS    = None     # Which layers to plot.  If None, all saved layers are plotted \n",
        "\n",
        "# Data structure used to store results -- add more measure[''] for multiple activations\n",
        "measures = OrderedDict()\n",
        "measures['softsign'] = {}\n",
        "measures['softplus'] = {}"
      ],
      "metadata": {
        "id": "8zftKKXGn-c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for activation in measures.keys():\n",
        "    cur_dir = 'rawdata/' + DIR_TEMPLATE % activation\n",
        "    if not os.path.exists(cur_dir):\n",
        "        print(\"Directory %s not found\" % cur_dir)\n",
        "        continue\n",
        "        \n",
        "    # Load files saved during each epoch, and compute MI measures of the activity in that epoch\n",
        "    print('*** Doing %s ***' % cur_dir)\n",
        "    for epochfile in sorted(os.listdir(cur_dir)):\n",
        "        if not epochfile.startswith('epoch'):\n",
        "            continue\n",
        "            \n",
        "        fname = cur_dir + \"/\" + epochfile\n",
        "        with open(fname, 'rb') as f:\n",
        "            d = cPickle.load(f)\n",
        "\n",
        "        epoch = d['epoch']\n",
        "        if epoch in measures[activation]: # Skip this epoch if its already been processed\n",
        "            continue                      # this is a trick to allow us to rerun this cell multiple times)\n",
        "            \n",
        "        if epoch > MAX_EPOCHS:\n",
        "            continue\n",
        "\n",
        "        print(\"Doing\", fname)\n",
        "        \n",
        "        num_layers = len(d['data']['activity_tst'])\n",
        "\n",
        "        if PLOT_LAYERS is None:\n",
        "            PLOT_LAYERS = []\n",
        "            for lndx in range(num_layers):\n",
        "                #if d['data']['activity_tst'][lndx].shape[1] < 200 and lndx != num_layers - 1:\n",
        "                PLOT_LAYERS.append(lndx)\n",
        "                \n",
        "        cepochdata = defaultdict(list)\n",
        "        for lndx in range(num_layers):\n",
        "            activity = d['data']['activity_tst'][lndx]\n",
        "\n",
        "            # Compute marginal entropies\n",
        "            h_upper = entropy_func_upper([activity,])[0]\n",
        "            if DO_LOWER:\n",
        "                h_lower = entropy_func_lower([activity,])[0]\n",
        "                \n",
        "            # Layer activity given input. This is simply the entropy of the Gaussian noise\n",
        "            hM_given_X = kde.kde_condentropy(activity, noise_variance)\n",
        "\n",
        "            # Compute conditional entropies of layer activity given output\n",
        "            hM_given_Y_upper=0.\n",
        "            for i in range(10):\n",
        "                hcond_upper = entropy_func_upper([activity[saved_labelixs[i],:],])[0]\n",
        "                hM_given_Y_upper += labelprobs[i] * hcond_upper\n",
        "                \n",
        "            if DO_LOWER:\n",
        "                hM_given_Y_lower=0.\n",
        "                for i in range(10):\n",
        "                    hcond_lower = entropy_func_lower([activity[saved_labelixs[i],:],])[0]\n",
        "                    hM_given_Y_lower += labelprobs[i] * hcond_lower\n",
        "                    \n",
        "                    \n",
        "            # # It's also possible to treat the last layer probabilistically. Here is the \n",
        "            # # code to do so. Should only be applied when lndx == num_layers - 1\n",
        "\n",
        "            # ps = activity.mean(axis=0)\n",
        "            # h_lower = h_upper = sum([-p*np.log(p) for p in ps if p != 0])\n",
        "\n",
        "            # x = -activity * np.log(activity)\n",
        "            # x[activity == 0] = 0.\n",
        "            # hM_given_X = np.mean(x.sum(axis=1))\n",
        "\n",
        "            # hM_given_Y=0.\n",
        "            # for i in range(10):\n",
        "            #     ixs = tst.y[::subsample] == i\n",
        "            #     ps = activity[ixs,:].mean(axis=0)\n",
        "            #     hcond = sum([-p*np.log(p) for p in ps if p != 0])\n",
        "            #     prob = np.mean(ixs)\n",
        "            #     hM_given_Y += l * hcond\n",
        "            # hM_given_Y_lower = hM_given_Y_upper = hM_given_Y\n",
        "            # del hM_given_Y\n",
        "                \n",
        "            cepochdata['MI_XM_upper'].append( nats2bits * (h_upper - hM_given_X) )\n",
        "            cepochdata['MI_YM_upper'].append( nats2bits * (h_upper - hM_given_Y_upper) )\n",
        "            cepochdata['H_M_upper'  ].append( nats2bits * h_upper )\n",
        "\n",
        "            pstr = 'upper: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_upper'][-1], cepochdata['MI_YM_upper'][-1])\n",
        "            if DO_LOWER:  # Compute lower bounds\n",
        "                cepochdata['MI_XM_lower'].append( nats2bits * (h_lower - hM_given_X) )\n",
        "                cepochdata['MI_YM_lower'].append( nats2bits * (h_lower - hM_given_Y_lower) )\n",
        "                cepochdata['H_M_lower'  ].append( nats2bits * h_lower )\n",
        "                pstr += ' | lower: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_lower'][-1], cepochdata['MI_YM_lower'][-1])\n",
        "\n",
        "            if DO_BINNED: # Compute binner estimates\n",
        "                binxm, binym = simplebinmi.bin_calc_information2(saved_labelixs, activity, 0.5)\n",
        "                cepochdata['MI_XM_bin'].append( nats2bits * binxm )\n",
        "                cepochdata['MI_YM_bin'].append( nats2bits * binym )\n",
        "                pstr += ' | bin: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_bin'][-1], cepochdata['MI_YM_bin'][-1])\n",
        "            \n",
        "            print('- Layer %d %s' % (lndx, pstr) )\n",
        "\n",
        "        measures[activation][epoch] = cepochdata"
      ],
      "metadata": {
        "id": "BwZG4_VGoO5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "max_epoch = max( (max(vals.keys()) if len(vals) else 0) for vals in measures.values())\n",
        "sm = plt.cm.ScalarMappable(cmap='gnuplot', norm=plt.Normalize(vmin=0, vmax=COLORBAR_MAX_EPOCHS))\n",
        "sm._A = []\n",
        "\n",
        "fig=plt.figure(figsize=(10,5))\n",
        "for actndx, (activation, vals) in enumerate(measures.items()):\n",
        "    epochs = sorted(vals.keys())\n",
        "    if not len(epochs):\n",
        "        continue\n",
        "    plt.subplot(1,2,actndx+1)    \n",
        "    for epoch in epochs:\n",
        "        c = sm.to_rgba(epoch)\n",
        "        xmvals = np.array(vals[epoch]['MI_XM_'+infoplane_measure])[PLOT_LAYERS]\n",
        "        ymvals = np.array(vals[epoch]['MI_YM_'+infoplane_measure])[PLOT_LAYERS]\n",
        "\n",
        "        plt.plot(xmvals, ymvals, c=c, alpha=0.1, zorder=1)\n",
        "        plt.scatter(xmvals, ymvals, s=20, facecolors=[c for _ in PLOT_LAYERS], edgecolor='none', zorder=2)\n",
        "    \n",
        "    plt.ylim([0, 3.5])\n",
        "    plt.xlim([0, 14])\n",
        "    plt.xlabel('I(X;M)')\n",
        "    plt.ylabel('I(Y;M)')\n",
        "    plt.title(activation)\n",
        "    \n",
        "cbaxes = fig.add_axes([1.0, 0.125, 0.03, 0.8]) \n",
        "plt.colorbar(sm, label='Epoch', cax=cbaxes)\n",
        "plt.tight_layout()\n",
        "\n",
        "!mkdir /content/plots\n",
        "if DO_SAVE:\n",
        "    plt.savefig('plots/' + DIR_TEMPLATE % ('infoplane_'+ARCH+cfg['ACTIVATION']+'MNIST batch'),bbox_inches='tight')\n",
        "\n",
        "!cp /content/plots -r drive/MyDrive/       "
      ],
      "metadata": {
        "id": "hTFmZQDKoaxA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "38f08eb45a74f8167b697f9534a4824a91b3f4ba83c913bdbd1160c52be203bb"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.10.4"
    },
    "colab": {
      "name": "MNIST_SaveActivations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}